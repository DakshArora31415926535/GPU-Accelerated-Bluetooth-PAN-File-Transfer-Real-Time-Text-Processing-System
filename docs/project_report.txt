Project Report
HYPERLINK-GPU: Bluetooth PAN Based File Transfer and CUDA-Accelerated Automated Typing System

1. Introduction
This project presents an end-to-end offline communication and automation system enabling text transfer between an Android phone and a Windows laptop using a Bluetooth Personal Area Network (PAN). The phone sends a text file to the laptop over a custom TCP protocol, and after reception, the laptop processes the text and automatically types it into the currently active window when the user presses the hotkey combination 7 + 8 + 9.
The system demonstrates low-level network programming, custom protocol design, OS-level automation, and multithreaded execution. In the updated version, the project incorporates a GPU-accelerated text processing pipeline using CUDA to achieve real-time large-scale text transformation before automated typing.

2. Motivation
Many real-world environments require peer-to-peer data exchange without internet availability, such as secure facilities, offline labs, temporary field deployments, and private communication scenarios. Bluetooth PAN provides a lightweight LAN-like environment without routers or external infrastructure.
Beyond data transfer, the project also aims to showcase applying GPU parallel computing to a real system, rather than isolated academic kernels. Processing text data (normalization, cleaning, analysis, and validation) can become slow on CPUs for large payloads or repeated transfers. Utilizing GPU parallelism drastically accelerates this stage while allowing the CPU to focus on networking and automation tasks.

3. System Architecture Overview
The high-level flow of the system is as follows:
Android phone (Termux) → Bluetooth PAN TCP connection → Windows receiver (C++ and WinSock2) → GPU text preprocessing using CUDA → Automated keystroke injection via SendInput → Output to any active window such as Notepad, browser, IDE, or chat application.

4. GPU Processing Pipeline
Once a payload is received, it is sent through a CUDA text processing stage that performs normalization, uppercasing, whitespace cleanup, character frequency analysis, and rolling hashing for integrity verification. Multiple GPU kernels operate in parallel to handle thousands of characters simultaneously, enabling sub-millisecond processing even for large files. This offloads intensive work from the CPU and keeps the networking and typing automation threads responsive.

5. Implementation
The receiver uses WinSock2 for reliable TCP communication, thread-safe file writing, UTF-8 to UTF-16 conversion, and hotkey detection. The sender, written in Python, reads a file, constructs a framed TCP message, and streams it to the receiver. The GPU component uses CUDA for parallel computation and pinned memory for efficient data transfer. SendInput enables automated keystroke synthesis into any active window.

6. Testing and Validation
The system was tested with small, medium, and large files, multiple transfers, interrupted transfers, and unstable Bluetooth conditions. GPU timing logs verify that parallel processing significantly reduces latency while maintaining consistent output quality.

7. Future Improvements
• GPU-based AES-256 encryption
• SHA-256 GPU integrity hashing
• Multi-file batch transmission
• Bidirectional communication
• CUDA stream-based pipelining
• GUI monitoring dashboard

8. Conclusion
HYPERLINK-GPU successfully demonstrates the integration of Bluetooth PAN networking, OS-level automation, and real GPU acceleration. The project transforms a simple data transfer mechanism into a high-performance hybrid computing system, proving that CUDA can deliver meaningful improvements in responsiveness and scalability within practical real-world applications.
